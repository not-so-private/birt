{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Parse IRT dataset from jsonlines, formatted in the following way:\n",
    "* The dataset is in jsonlines format, each line representing the responses of a subject\n",
    "* Each row looks like this:\n",
    "{\"subject_id\": \"<subject_id>\", \"responses\": {\"<item_id>\": <response>}}\n",
    "* Where <subject_id> is a string, <item_id> is a string, and <response> is a number (usually integer)\n",
    "```  \n",
    "- mengubah value table dengan perkiraan ini  \n",
    "![](images/estimasi_level.png)\n",
    "- filter data pemain dengan kondisi clear > 0 and minbp < notes * 0.2\n",
    "- easy clear = jadikan player dengan clear >= 2 jadi 1 jika tidak 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olah data\n",
    "## Download table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "sources = {\n",
    "    \"Satellite\": \"https://stellabms.xyz/sl/score.json\",\n",
    "    \"Stella\": \"https://stellabms.xyz/st/score.json\",\n",
    "    \"Insane1\": \"http://www.ribbit.xyz/bms/tables/insane_body.json\",\n",
    "    \"Insane2\": \"https://rattoto10.github.io/second_table/insane_data.json\",\n",
    "}\n",
    "\n",
    "output_paths = {\n",
    "    \"Satellite\": \"dataset/table_ori/satellite.json\",\n",
    "    \"Stella\": \"dataset/table_ori/stella.json\",\n",
    "    \"Insane1\": \"dataset/table_ori/insane1.json\",\n",
    "    \"Insane2\": \"dataset/table_ori/insane2.json\",\n",
    "}\n",
    "\n",
    "for source_name, source_url in sources.items():\n",
    "    response = requests.get(source_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response.encoding = 'utf-8'\n",
    "\n",
    "        json_data = response.json()\n",
    "\n",
    "        output_path = output_paths[source_name]\n",
    "        with open(output_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(response.text)\n",
    "\n",
    "        print(f\"Downloaded and saved {source_name} JSON data to {output_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve {source_name} JSON data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ganti level table dan gabungkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dataset_paths = [\"dataset/table_ori/insane1.json\", \"dataset/table_ori/insane2.json\", \"dataset/table_ori/satellite.json\", \"dataset/table_ori/stella.json\"]\n",
    "combined_data = {}\n",
    "\n",
    "def transform_level(dataset_name, level):\n",
    "    \n",
    "    if level.isdigit(): \n",
    "        level = int(level)\n",
    "    else:\n",
    "        level = 0 \n",
    "    \n",
    "    if dataset_name == \"insane1.json\":\n",
    "        return level + 11\n",
    "    elif dataset_name == \"insane2.json\":\n",
    "        if level == \"0-\":\n",
    "            return 11.5\n",
    "        elif level == \"0\":\n",
    "            return 11.8\n",
    "        else:\n",
    "            return level + 11\n",
    "    elif dataset_name == \"satellite.json\":\n",
    "        return [0.5, 1.5, 3, 4.5, 6.5, 8.5, 10.5, 12, 13.5, 15.5, 16.5, 17.5, 19][level] + 11\n",
    "    elif dataset_name == \"stella.json\":\n",
    "        return [19.5, 21, 22, 22.5, 23.5, 24, 24.25, 24.5, 24.75, 25, 25.5, 26, 27, 27.5][level] + 11\n",
    "\n",
    "for dataset_path in reversed(dataset_paths):  \n",
    "    with open(dataset_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        dataset = json.load(file)\n",
    "\n",
    "    for item in dataset:\n",
    "        md5 = item[\"md5\"]\n",
    "        level = item[\"level\"]\n",
    "\n",
    "        item[\"level\"] = transform_level(dataset_path.split(\"/\")[-1], level)\n",
    "\n",
    "        if md5 in combined_data:\n",
    "            combined_data[md5] = item\n",
    "        else:\n",
    "            combined_data[md5] = item \n",
    "\n",
    "combined_data_list = list(combined_data.values())\n",
    "\n",
    "with open(\"dataset/combined_dataset.json\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    json.dump(combined_data_list, outfile, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dapatkan player score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "def fetch_scores_for_md5(md5, cache_dir):\n",
    "    cache_file = os.path.join(cache_dir, f'{md5}.json')\n",
    "\n",
    "    try:\n",
    "        with open(cache_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        if not isinstance(data, list):\n",
    "            raise ValueError(f'Invalid cache for {md5}')\n",
    "\n",
    "        return data\n",
    "    except (FileNotFoundError, ValueError):\n",
    "        response = requests.get(f'http://dream-pro.info/~lavalse/LR2IR/2/getrankingxml.cgi?songmd5={md5}&id=1')\n",
    "        response_text = response.text\n",
    "\n",
    "        xml_start = response_text.find('<?xml')\n",
    "        xml_end = response_text.rfind('</ranking>') + len('</ranking>')\n",
    "        if xml_start != -1 and xml_end != -1:\n",
    "            xml_text = response_text[xml_start:xml_end]\n",
    "        else:\n",
    "            raise ValueError(f'Invalid XML response for {md5}')\n",
    "\n",
    "        xml_root = ET.fromstring(xml_text)\n",
    "        data = []\n",
    "\n",
    "        for score_elem in xml_root.findall('.//score'):\n",
    "            score_data = {\n",
    "                'name': score_elem.find('name').text,\n",
    "                'id': int(score_elem.find('id').text),\n",
    "                'clear': int(score_elem.find('clear').text),\n",
    "                'notes': int(score_elem.find('notes').text),\n",
    "                'combo': int(score_elem.find('combo').text),\n",
    "                'pg': int(score_elem.find('pg').text),\n",
    "                'gr': int(score_elem.find('gr').text),\n",
    "                'minbp': int(score_elem.find('minbp').text),\n",
    "            }\n",
    "            data.append(score_data)\n",
    "\n",
    "        for d in data:\n",
    "            d['name'] = str(d['name'])\n",
    "\n",
    "        with open(cache_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent='\\t')\n",
    "\n",
    "        return data\n",
    "\n",
    "def get_scores_for_md5(md5, cache_dir):\n",
    "    tries = 0\n",
    "\n",
    "    while tries < 3:\n",
    "        try:\n",
    "            data = fetch_scores_for_md5(md5, cache_dir)\n",
    "            return data\n",
    "        except Exception as err:\n",
    "            tries += 1\n",
    "            sleep_time = (1000 * tries + (0.5 - 1) * 1000) * 2\n",
    "            print(f'Got throttled ({md5}): Sleeping for {sleep_time:.0f}ms. {err}')\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "    raise Exception(f\"Couldn't fetch data in 3 tries. Giving up and exiting.\")\n",
    "\n",
    "cache_directory = \"dataset/lr2ir\" \n",
    "\n",
    "md5_values = []\n",
    "\n",
    "json_files = [\"dataset/combined_dataset.json\"]\n",
    "for json_file in json_files:\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        for item in data:\n",
    "            md5_values.append(item['md5'])\n",
    "\n",
    "for md5 in md5_values:\n",
    "    scores = get_scores_for_md5(md5, cache_directory)\n",
    "    print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter dataset dengan kondisi clear > 0 and minbp < notes * 0.2\n",
    "0 = no play  \n",
    "1 = failed  \n",
    "2 = easy clear  \n",
    "3 = normal clear  \n",
    "4 = hard clear  \n",
    "5 = full combo  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "with open(\"dataset/combined_dataset.json\", \"r\", encoding=\"utf-8\") as combined_file:\n",
    "    combined_data = json.load(combined_file)\n",
    "\n",
    "def filter_and_save_dataset(md5):\n",
    "    dataset_path = f\"dataset/lr2ir/{md5}.json\"\n",
    "    if os.path.exists(dataset_path):\n",
    "        with open(dataset_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            dataset = json.load(file)\n",
    "\n",
    "        filtered_dataset = [item for item in dataset if item[\"clear\"] > 0 and item[\"minbp\"] < item[\"notes\"] * 0.2]\n",
    "\n",
    "        filtered_path = f\"dataset/filtered_lr2ir/{md5}.json\"\n",
    "        with open(filtered_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "            json.dump(filtered_dataset, outfile, ensure_ascii=False, indent=2)\n",
    "    else:\n",
    "        print(f\"Dataset not found for MD5: {md5}\")\n",
    "\n",
    "for item in combined_data:\n",
    "    md5 = item[\"md5\"]\n",
    "    filter_and_save_dataset(md5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Akuisisi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "with open(\"dataset/combined_dataset.json\", \"r\", encoding=\"utf-8\") as combined_file:\n",
    "    combined_data = json.load(combined_file)\n",
    "\n",
    "def process_subject_responses(md5):\n",
    "    response_dict = {\"subject_id\": md5, \"responses\": {}}\n",
    "\n",
    "    dataset_path = f\"dataset/filtered_lr2ir/{md5}.json\"\n",
    "    if os.path.exists(dataset_path):\n",
    "        with open(dataset_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            dataset = json.load(file)\n",
    "\n",
    "        for item in dataset:\n",
    "            item_id = str(item[\"id\"])\n",
    "            clear = item[\"clear\"]\n",
    "            response = 1 if clear >= 2 else 0\n",
    "            response_dict[\"responses\"][item_id] = response\n",
    "\n",
    "        with open(\"dataset/easy_dataset.jsonlines\", \"a\", encoding=\"utf-8\") as outfile:\n",
    "            json.dump(response_dict, outfile, ensure_ascii=False)\n",
    "            outfile.write(\"\\n\")\n",
    "    else:\n",
    "        print(f\"Filtered dataset not found for MD5: {md5}\")\n",
    "\n",
    "for item in combined_data:\n",
    "    md5 = item[\"md5\"]\n",
    "    process_subject_responses(md5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "with open(\"dataset/combined_dataset.json\", \"r\", encoding=\"utf-8\") as combined_file:\n",
    "    combined_data = json.load(combined_file)\n",
    "\n",
    "def process_subject_responses(md5):\n",
    "    response_dict = {\"subject_id\": md5, \"responses\": {}}\n",
    "\n",
    "    dataset_path = f\"dataset/filtered_lr2ir/{md5}.json\"\n",
    "    if os.path.exists(dataset_path):\n",
    "        with open(dataset_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            dataset = json.load(file)\n",
    "\n",
    "        for item in dataset:\n",
    "            item_id = str(item[\"id\"])\n",
    "            clear = item[\"clear\"]\n",
    "            response = 1 if clear >= 4 else 0\n",
    "            response_dict[\"responses\"][item_id] = response\n",
    "\n",
    "        with open(\"dataset/hard_dataset.jsonlines\", \"a\", encoding=\"utf-8\") as outfile:\n",
    "            json.dump(response_dict, outfile, ensure_ascii=False)\n",
    "            outfile.write(\"\\n\")\n",
    "    else:\n",
    "        print(f\"Filtered dataset not found for MD5: {md5}\")\n",
    "\n",
    "for item in combined_data:\n",
    "    md5 = item[\"md5\"]\n",
    "    process_subject_responses(md5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run py-irt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train dan evaluasi data\n",
    "By default this will train a model with 90% of the provided data and evaluate with the remaining 10% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                               \n",
      " Usage: py-irt.cmd train-and-evaluate [OPTIONS] MODEL_TYPE DATA_PATH           \n",
      " OUTPUT_DIR                                                                    \n",
      "                                                                               \n",
      "┌─ Arguments ─────────────────────────────────────────────────────────────────┐\n",
      "│ *    model_type      TEXT  [default: None] [required]                       │\n",
      "│ *    data_path       TEXT  [default: None] [required]                       │\n",
      "│ *    output_dir      TEXT  [default: None] [required]                       │\n",
      "└─────────────────────────────────────────────────────────────────────────────┘\n",
      "┌─ Options ───────────────────────────────────────────────────────────────────┐\n",
      "│ --epochs              INTEGER  [default: 2000]                              │\n",
      "│ --priors              TEXT     [default: None]                              │\n",
      "│ --dims                INTEGER  [default: None]                              │\n",
      "│ --device              TEXT     [default: cpu]                               │\n",
      "│ --lr                  FLOAT    [default: None]                              │\n",
      "│ --lr-decay            FLOAT    [default: None]                              │\n",
      "│ --initializers        TEXT     [default: None]                              │\n",
      "│ --evaluation          TEXT     [default: heldout]                           │\n",
      "│ --seed                INTEGER  [default: 42]                                │\n",
      "│ --train-size          FLOAT    [default: 0.9]                               │\n",
      "│ --config-path         TEXT     [default: None]                              │\n",
      "│ --dropout             FLOAT    [default: 0.5]                               │\n",
      "│ --hidden              INTEGER  [default: 100]                               │\n",
      "│ --help                         Show this message and exit.                  │\n",
      "└─────────────────────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!poetry run py-irt train-and-evaluate --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: py-irt.cmd evaluate [OPTIONS] MODEL_TYPE PARAMETER_PATH TEST_PAIRS_PATH\n",
      "                           OUTPUT_DIR\n",
      "\n",
      "Arguments:\n",
      "  MODEL_TYPE       [required]\n",
      "  PARAMETER_PATH   [required]\n",
      "  TEST_PAIRS_PATH  [required]\n",
      "  OUTPUT_DIR       [required]\n",
      "\n",
      "Options:\n",
      "  --epochs INTEGER     [default: 2000]\n",
      "  --device TEXT        [default: cpu]\n",
      "  --initializers TEXT\n",
      "  --evaluation TEXT    [default: heldout]\n",
      "  --seed INTEGER       [default: 42]\n",
      "  --train-size FLOAT   [default: 0.9]\n",
      "  --help               Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!poetry run py-irt evaluate --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:45:41] config: model_type='2pl' epochs=2000 priors=None          cli.py:176\n",
      "           initializers=[] dims=None lr=0.1 lr_decay=0.9999                    \n",
      "           dropout=0.5 hidden=100 vocab_size=None log_every=100                \n",
      "           seed=None deterministic=False                                       \n",
      "           data_path: dataset/easy_dataset.jsonlines                 cli.py:178\n",
      "           output directory: 2pl/easyx/                              cli.py:179\n",
      "[07:45:55] amortized: False                                      dataset.py:112\n",
      "[07:46:35] Vocab size: None                                      training.py:90\n",
      "[07:46:37] Training Model...                                         cli.py:209\n",
      "[07:46:37] args: {'device': 'cpu', 'num_items': 52766,          training.py:134\n",
      "           'num_subjects': 5230}                                               \n",
      "           Parsed Model Args: {'device': 'cpu', 'num_items':    training.py:147\n",
      "           52766, 'num_subjects': 5230, 'priors': 'vague',                     \n",
      "           'dropout': 0.5, 'hidden': 100, 'vocab_size': None}                  \n",
      "torch.Size([8419626]) torch.Size([8419626])\n",
      "Training Pyro IRT Model for 2000 epochs\n",
      "┌───────┬────────────────┬────────────────┬────────┐\n",
      "│ Epoch │ Loss           │ Best Loss      │ New LR │\n",
      "├───────┼────────────────┼────────────────┼────────┤\n",
      "│ 1     │ 302960796.5000 │ 302960796.5000 │ 0.1000 │\n",
      "│ 101   │ 6981442.2893   │ 6981442.2893   │ 0.0990 │\n",
      "│ 201   │ 4409905.5084   │ 4409905.5084   │ 0.0980 │\n",
      "│ 301   │ 3646843.1492   │ 3641726.4314   │ 0.0970 │\n",
      "│ 401   │ 3287753.8529   │ 3287753.8529   │ 0.0961 │\n",
      "│ 501   │ 3088164.6088   │ 3084597.7199   │ 0.0951 │\n",
      "│ 601   │ 2967896.3653   │ 2965564.2104   │ 0.0942 │\n",
      "│ 701   │ 2885204.2970   │ 2881658.5183   │ 0.0932 │\n",
      "│ 801   │ 2828626.8317   │ 2826174.8159   │ 0.0923 │\n",
      "│ 901   │ 2786717.6446   │ 2784856.9798   │ 0.0914 │\n",
      "│ 1001  │ 2757321.3076   │ 2753589.6528   │ 0.0905 │\n",
      "│ 1101  │ 2731707.2041   │ 2731210.7344   │ 0.0896 │\n",
      "│ 1201  │ 2711477.0802   │ 2711477.0802   │ 0.0887 │\n",
      "│ 1301  │ 2697519.4377   │ 2697519.4377   │ 0.0878 │\n",
      "│ 1401  │ 2687250.6284   │ 2686548.4478   │ 0.0869 │\n",
      "│ 1501  │ 2677126.0759   │ 2677126.0759   │ 0.0861 │\n",
      "│ 1601  │ 2670560.4335   │ 2669098.4573   │ 0.0852 │\n",
      "│ 1701  │ 2663706.8694   │ 2663038.4492   │ 0.0844 │\n",
      "│ 1801  │ 2658282.8862   │ 2657768.7310   │ 0.0835 │\n",
      "│ 1901  │ 2653792.9681   │ 2653792.9681   │ 0.0827 │\n",
      "│ 2000  │ 2650917.3143   │ 2650297.4106   │ 0.0819 │\n",
      "└───────┴────────────────┴────────────────┴────────┘[07:54:49] Evaluating Model...                                       cli.py:216\n",
      "[07:54:53] Evaluation time: 552.8819530010223                        cli.py:244\n"
     ]
    }
   ],
   "source": [
    "!poetry run py-irt train-and-evaluate 2pl dataset/easy_dataset.jsonlines 2pl/easyx/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:07:21] config: model_type='2pl' epochs=2000 priors=None          cli.py:176\n",
      "           initializers=[] dims=None lr=0.1 lr_decay=0.9999                    \n",
      "           dropout=0.5 hidden=100 vocab_size=None log_every=100                \n",
      "           seed=None deterministic=False                                       \n",
      "           data_path: dataset/hard_dataset.jsonlines                 cli.py:178\n",
      "           output directory: 2pl/hardx/                              cli.py:179\n",
      "[09:07:36] amortized: False                                      dataset.py:112\n",
      "[09:08:15] Vocab size: None                                      training.py:90\n",
      "[09:08:18] Training Model...                                         cli.py:209\n",
      "[09:08:18] args: {'device': 'cpu', 'num_items': 52766,          training.py:134\n",
      "           'num_subjects': 5230}                                               \n",
      "           Parsed Model Args: {'device': 'cpu', 'num_items':    training.py:147\n",
      "           52766, 'num_subjects': 5230, 'priors': 'vague',                     \n",
      "           'dropout': 0.5, 'hidden': 100, 'vocab_size': None}                  \n",
      "torch.Size([8419626]) torch.Size([8419626])\n",
      "Training Pyro IRT Model for 2000 epochs\n",
      "┌───────┬────────────────┬────────────────┬────────┐\n",
      "│ Epoch │ Loss           │ Best Loss      │ New LR │\n",
      "├───────┼────────────────┼────────────────┼────────┤\n",
      "│ 1     │ 301390244.7500 │ 301390244.7500 │ 0.1000 │\n",
      "│ 101   │ 8266434.2793   │ 8266434.2793   │ 0.0990 │\n",
      "│ 201   │ 5620051.8258   │ 5620051.8258   │ 0.0980 │\n",
      "│ 301   │ 4816263.7195   │ 4813714.6388   │ 0.0970 │\n",
      "│ 401   │ 4444109.0101   │ 4433158.2487   │ 0.0961 │\n",
      "│ 501   │ 4233532.4849   │ 4233532.4849   │ 0.0951 │\n",
      "│ 601   │ 4115674.6724   │ 4115454.2489   │ 0.0942 │\n",
      "│ 701   │ 4034011.7837   │ 4032939.9922   │ 0.0932 │\n",
      "│ 801   │ 3972766.3181   │ 3972766.3181   │ 0.0923 │\n",
      "│ 901   │ 3941248.7478   │ 3936069.2620   │ 0.0914 │\n",
      "│ 1001  │ 3906130.9608   │ 3906130.9608   │ 0.0905 │\n",
      "│ 1101  │ 3884884.6887   │ 3881219.9955   │ 0.0896 │\n",
      "│ 1201  │ 3865901.9595   │ 3864145.5166   │ 0.0887 │\n",
      "│ 1301  │ 3848234.4234   │ 3848234.4234   │ 0.0878 │\n",
      "│ 1401  │ 3839199.7517   │ 3836808.2665   │ 0.0869 │\n",
      "│ 1501  │ 3828400.1494   │ 3827631.5312   │ 0.0861 │\n",
      "│ 1601  │ 3823803.3793   │ 3819101.7956   │ 0.0852 │\n",
      "│ 1701  │ 3815024.0968   │ 3814996.6208   │ 0.0844 │\n",
      "│ 1801  │ 3809689.7800   │ 3808438.7551   │ 0.0835 │\n",
      "│ 1901  │ 3805967.0772   │ 3804620.5121   │ 0.0827 │\n",
      "│ 2000  │ 3803685.9838   │ 3800328.3640   │ 0.0819 │\n",
      "└───────┴────────────────┴────────────────┴────────┘[09:16:40] Evaluating Model...                                       cli.py:216\n",
      "[09:16:44] Evaluation time: 562.9868953227997                        cli.py:244\n"
     ]
    }
   ],
   "source": [
    "!poetry run py-irt train-and-evaluate 2pl dataset/hard_dataset.jsonlines 2pl/hardx/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in 'ability': 5230\n",
      "Number of items in 'diff': 52766\n",
      "Number of items in 'disc': 52766\n",
      "Number of items in 'item_ids': 52766\n",
      "Number of items in 'subject_ids': 5230\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('2pl/easyx/best_parameters.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Count the number of items in each dictionary\n",
    "num_ability_items = len(data[\"ability\"])\n",
    "num_diff_items = len(data[\"diff\"])\n",
    "num_disc_items = len(data[\"disc\"])\n",
    "num_item_ids = len(data[\"item_ids\"])\n",
    "num_subject_ids = len(data[\"subject_ids\"])\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Number of items in 'ability': {num_ability_items}\")\n",
    "print(f\"Number of items in 'diff': {num_diff_items}\")\n",
    "print(f\"Number of items in 'disc': {num_disc_items}\")\n",
    "print(f\"Number of items in 'item_ids': {num_item_ids}\")\n",
    "print(f\"Number of items in 'subject_ids': {num_subject_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in 'ability': 5230\n",
      "Number of items in 'diff': 52766\n",
      "Number of items in 'disc': 52766\n",
      "Number of items in 'item_ids': 52766\n",
      "Number of items in 'subject_ids': 5230\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('2pl/hardx/best_parameters.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Count the number of items in each dictionary\n",
    "num_ability_items = len(data[\"ability\"])\n",
    "num_diff_items = len(data[\"diff\"])\n",
    "num_disc_items = len(data[\"disc\"])\n",
    "num_item_ids = len(data[\"item_ids\"])\n",
    "num_subject_ids = len(data[\"subject_ids\"])\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Number of items in 'ability': {num_ability_items}\")\n",
    "print(f\"Number of items in 'diff': {num_diff_items}\")\n",
    "print(f\"Number of items in 'disc': {num_disc_items}\")\n",
    "print(f\"Number of items in 'item_ids': {num_item_ids}\")\n",
    "print(f\"Number of items in 'subject_ids': {num_subject_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output hasil\n",
    "\n",
    "### Easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for est_level: 0.03363296658688851\n",
      "                                   md5  \\\n",
      "4257  bed8c515b04d9fa79d19d51a57890a28   \n",
      "4258  508330b4bc4513536aea7945d90909e2   \n",
      "4256  975edffb868ef4d1cde4b845022ea316   \n",
      "1475  b341e4cc6f0f6a59100910ed11a92f8d   \n",
      "2965  03c906bf1229a701a0471165242e1233   \n",
      "...                                ...   \n",
      "1386  fed59d3b700499c9207c4995d160cc9a   \n",
      "1381  8fdd4ffb45d79ef2e713a01abc9a08c3   \n",
      "1383  e01344b7d64159e7aa28b29d32ea6351   \n",
      "1382  bb843baa1332cdacd049f1e142c79045   \n",
      "1384  f880de58c2dcb3ea4e3d9dc39b096080   \n",
      "\n",
      "                                                  title  base_level  \\\n",
      "4257                  さいこ゛のたたかい /たひ゛のおわり [7Key Another]        11.0   \n",
      "4258                                            マジカル縦連打        11.0   \n",
      "4256                            Thrill Trigger EX2 YPER        11.0   \n",
      "1475                               Lieselotte [ANOTHER]        11.0   \n",
      "2965                                Pure Ruby [Another]        11.0   \n",
      "...                                                 ...         ...   \n",
      "1386                   the lost dedicated [life normal]        38.0   \n",
      "1381                                Dusk Recapture [AB]        38.0   \n",
      "1383  Nyan-Nyan Naughty Night [N,N,N′,N′-Tetramethyl...        38.0   \n",
      "1382                                    MESMERA [KOOKY]        38.0   \n",
      "1384                      saucy plume (KurisumasuFumen)        38.0   \n",
      "\n",
      "      prediction    ability  player_count  clear_count  est_level  \n",
      "4257    0.914496   0.953454        1236.0       1173.0  10.946203  \n",
      "4258    0.908785   4.697621        1205.0       1144.0  10.951914  \n",
      "4256    0.891855   0.472832        1245.0       1175.0  10.968845  \n",
      "1475    0.889777  13.756712         164.0        159.0  10.970922  \n",
      "2965    0.889685   8.044311           2.0          2.0  10.971014  \n",
      "...          ...        ...           ...          ...        ...  \n",
      "1386    0.829124  -2.275541          19.0         16.0  38.000000  \n",
      "1381    0.270609  -3.370217           2.0          1.0  38.000000  \n",
      "1383    0.203749  -2.772997           1.0          0.0  38.044556  \n",
      "1382    0.159601  -1.768321           1.0          0.0  38.088704  \n",
      "1384    0.073941  -2.553566           1.0          0.0  38.174364  \n",
      "\n",
      "[5194 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "with open('dataset/combined_dataset.json', 'r', encoding=\"utf-8\") as chart_file:\n",
    "    combined_data = json.load(chart_file)\n",
    "\n",
    "best_parameters = []\n",
    "with open('2pl/easyx/best_parameters.json', 'r', encoding=\"utf-8\") as parameters_file:\n",
    "    for line in parameters_file:\n",
    "        params = json.loads(line)\n",
    "        abilities = params['ability']\n",
    "        for subject_id, ability in zip(params['subject_ids'].values(), abilities):\n",
    "            best_parameters.append({'subject_id': subject_id, 'ability': ability})\n",
    "\n",
    "model_predictions = []\n",
    "with open('2pl/easyx/model_predictions.jsonlines', 'r', encoding=\"utf-8\") as predictions_file:\n",
    "    for line in predictions_file:\n",
    "        model_predictions.append(json.loads(line))\n",
    "\n",
    "combined_df = pd.DataFrame(combined_data)\n",
    "parameters_df = pd.DataFrame(best_parameters)\n",
    "predictions_df = pd.DataFrame(model_predictions)\n",
    "\n",
    "predictions_df.dropna(subset=['prediction'], inplace=True)\n",
    "\n",
    "summary_df = predictions_df.groupby('subject_id').agg({'response': lambda x: (x == 1).sum(), 'prediction': ['mean', 'count']}).reset_index()\n",
    "summary_df.columns = ['subject_id', 'clear', 'average_prediction', 'playercount']\n",
    "\n",
    "summary_df['subject_id'] = summary_df['subject_id'].astype(str)\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'md5': combined_df['md5'],\n",
    "    'title': combined_df['title'],\n",
    "    'base_level': combined_df['level'],\n",
    "    'prediction': summary_df['average_prediction'],\n",
    "    'ability': parameters_df['ability'],\n",
    "    'player_count': summary_df['playercount'],\n",
    "    'clear_count': summary_df['clear']\n",
    "})\n",
    "result_df.dropna(inplace=True)\n",
    "\n",
    "def calculate_est_level(row):\n",
    "    base_level = row['base_level']\n",
    "    prediction = row['prediction']\n",
    "    \n",
    "    mid_zone_start = np.percentile(result_df[result_df['base_level'] == base_level]['prediction'], 33.33)\n",
    "    mid_zone_end = np.percentile(result_df[result_df['base_level'] == base_level]['prediction'], 66.67)\n",
    "\n",
    "    if prediction <= mid_zone_start:\n",
    "        return base_level + (mid_zone_start - prediction)\n",
    "    elif mid_zone_start < prediction <= mid_zone_end:\n",
    "        return base_level\n",
    "    else:\n",
    "        return base_level - (prediction - mid_zone_end)\n",
    "\n",
    "result_df['est_level'] = result_df.apply(calculate_est_level, axis=1)\n",
    "result_df.sort_values(by='est_level', ascending=True, inplace=True)\n",
    "\n",
    "mae_est_level = mean_absolute_error(result_df['base_level'], result_df['est_level'])\n",
    "print(\"MAE for est_level:\", mae_est_level)\n",
    "\n",
    "result_df.to_csv('output/easy_output_final.csv', index=False)\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "#result_df.to_csv('output/easy_output_final.csv', index=False)\n",
    "df = pd.read_csv('output/easy_output_final.csv')\n",
    "\n",
    "html_table = tabulate(df, headers='keys', tablefmt='html')\n",
    "\n",
    "styled_html_table = f'''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Easy Clear Estimation</title>\n",
    "    <style>\n",
    "        table {{border-collapse: collapse; border: 2px solid black;}}\n",
    "        th, td {{border: 1px solid black; padding: 10px;}}\n",
    "        tr:nth-child(even) {{background-color: #ff9393;}}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Easy Clear Estimation</h1>\n",
    "    {html_table}\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "with open('output/easy_output_final.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(styled_html_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for est_level: 0.039402934422971686\n",
      "                                   md5  \\\n",
      "2965  03c906bf1229a701a0471165242e1233   \n",
      "2961  a23ea067c01254f860a55171dbee4f89   \n",
      "2971  8bdc1d1fe654d75136173211f124ad70   \n",
      "4257  bed8c515b04d9fa79d19d51a57890a28   \n",
      "4258  508330b4bc4513536aea7945d90909e2   \n",
      "...                                ...   \n",
      "1386  fed59d3b700499c9207c4995d160cc9a   \n",
      "1383  e01344b7d64159e7aa28b29d32ea6351   \n",
      "1381  8fdd4ffb45d79ef2e713a01abc9a08c3   \n",
      "1382  bb843baa1332cdacd049f1e142c79045   \n",
      "1384  f880de58c2dcb3ea4e3d9dc39b096080   \n",
      "\n",
      "                                                  title  base_level  \\\n",
      "2965                                Pure Ruby [Another]        11.0   \n",
      "2961                          Master of GENOCIDE [発狂入門]        11.0   \n",
      "2971                                 コスモワンダラー [SAETHER]        11.0   \n",
      "4257                  さいこ゛のたたかい /たひ゛のおわり [7Key Another]        11.0   \n",
      "4258                                            マジカル縦連打        11.0   \n",
      "...                                                 ...         ...   \n",
      "1386                   the lost dedicated [life normal]        38.0   \n",
      "1383  Nyan-Nyan Naughty Night [N,N,N′,N′-Tetramethyl...        38.0   \n",
      "1381                                Dusk Recapture [AB]        38.0   \n",
      "1382                                    MESMERA [KOOKY]        38.0   \n",
      "1384                      saucy plume (KurisumasuFumen)        38.0   \n",
      "\n",
      "      prediction   ability  player_count  clear_count  est_level  \n",
      "2965    0.896169  3.427751           2.0          2.0  10.834541  \n",
      "2961    0.879120  4.897824           3.0          3.0  10.851590  \n",
      "2971    0.859551  3.860892           1.0          1.0  10.871159  \n",
      "4257    0.784687 -0.243510        1236.0        985.0  10.946023  \n",
      "4258    0.783708  0.943088        1205.0        904.0  10.947003  \n",
      "...          ...       ...           ...          ...        ...  \n",
      "1386    0.770958 -3.269377          19.0         15.0  38.000000  \n",
      "1383    0.287263 -3.582881           1.0          0.0  38.000000  \n",
      "1381    0.286962 -3.954045           2.0          0.0  38.000200  \n",
      "1382    0.232156 -1.981480           1.0          0.0  38.055007  \n",
      "1384    0.089361 -3.558089           1.0          0.0  38.197801  \n",
      "\n",
      "[5194 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "with open('dataset/combined_dataset.json', 'r', encoding=\"utf-8\") as chart_file:\n",
    "    combined_data = json.load(chart_file)\n",
    "\n",
    "best_parameters = []\n",
    "with open('2pl/hardx/best_parameters.json', 'r', encoding=\"utf-8\") as parameters_file:\n",
    "    for line in parameters_file:\n",
    "        params = json.loads(line)\n",
    "        abilities = params['ability']\n",
    "        for subject_id, ability in zip(params['subject_ids'].values(), abilities):\n",
    "            best_parameters.append({'subject_id': subject_id, 'ability': ability})\n",
    "            \n",
    "model_predictions = []\n",
    "with open('2pl/hardx/model_predictions.jsonlines', 'r', encoding=\"utf-8\") as predictions_file:\n",
    "    for line in predictions_file:\n",
    "        model_predictions.append(json.loads(line))\n",
    "\n",
    "combined_df = pd.DataFrame(combined_data)\n",
    "parameters_df = pd.DataFrame(best_parameters)\n",
    "predictions_df = pd.DataFrame(model_predictions)\n",
    "\n",
    "predictions_df.dropna(subset=['prediction'], inplace=True)\n",
    "\n",
    "summary_df = predictions_df.groupby('subject_id').agg({'response': lambda x: (x == 1).sum(), 'prediction': ['mean', 'count']}).reset_index()\n",
    "summary_df.columns = ['subject_id', 'clear', 'average_prediction', 'playercount']\n",
    "\n",
    "summary_df['subject_id'] = summary_df['subject_id'].astype(str)\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'md5': combined_df['md5'],\n",
    "    'title': combined_df['title'],\n",
    "    'base_level': combined_df['level'],\n",
    "    'prediction': summary_df['average_prediction'],\n",
    "    'ability': parameters_df['ability'],\n",
    "    'player_count': summary_df['playercount'],\n",
    "    'clear_count': summary_df['clear']\n",
    "})\n",
    "result_df.dropna(inplace=True)\n",
    "\n",
    "def calculate_est_level(row):\n",
    "    base_level = row['base_level']\n",
    "    prediction = row['prediction']\n",
    "    \n",
    "    mid_zone_start = np.percentile(result_df[result_df['base_level'] == base_level]['prediction'], 33.33)\n",
    "    mid_zone_end = np.percentile(result_df[result_df['base_level'] == base_level]['prediction'], 66.67)\n",
    "\n",
    "    if prediction <= mid_zone_start:\n",
    "        return base_level + (mid_zone_start - prediction)\n",
    "    elif mid_zone_start < prediction <= mid_zone_end:\n",
    "        return base_level\n",
    "    else:\n",
    "        return base_level - (prediction - mid_zone_end)\n",
    "\n",
    "result_df['est_level'] = result_df.apply(calculate_est_level, axis=1)\n",
    "result_df.sort_values(by='est_level', ascending=True, inplace=True)\n",
    "\n",
    "mae_est_level = mean_absolute_error(result_df['base_level'], result_df['est_level'])\n",
    "print(\"MAE for est_level:\", mae_est_level)\n",
    "\n",
    "result_df.to_csv('output/hard_output_final.csv', index=False)\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "df = pd.read_csv('output/hard_output_final.csv')\n",
    "\n",
    "html_table = tabulate(df, headers='keys', tablefmt='html')\n",
    "\n",
    "styled_html_table = f'''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Hard Clear Estimation</title>\n",
    "    <style>\n",
    "        table {{border-collapse: collapse; border: 2px solid black;}}\n",
    "        th, td {{border: 1px solid black; padding: 10px;}}\n",
    "        tr:nth-child(even) {{background-color: #ff9393;}}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Hard Clear Estimation</h1>\n",
    "    {html_table}\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "with open('output/hard_output_final.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(styled_html_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-irt-hOXkc2ls-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
